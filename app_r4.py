import streamlit as st
import numpy as np
import pandas as pd
import pickle
import torch
import os
import queue
import av
from collections import deque
from ultralytics import YOLO
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration

# ==========================================
# 0. í™˜ê²½ ë° ê²½ë¡œ ì„¤ì •
# ==========================================
st.set_page_config(page_title="Phisio AI Pro (Cloud)", layout="wide")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
POSE_MODEL_NAME = os.path.join(BASE_DIR, "yolov8n-pose.pt")
ACTION_WEIGHTS_PATH = os.path.join(BASE_DIR, "yoga_weights_yolo_seated_safe.pkl")
STICKER_MODEL_PATH = os.path.join(BASE_DIR, 'best.pt')

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

if 'result_queue' not in st.session_state:
    st.session_state.result_queue = queue.Queue(maxsize=1)

# ==========================================
# 1. ëª¨ë¸ ë° ì²˜ë¦¬ í´ë˜ìŠ¤ (Lazy Loading ì ìš©)
# ==========================================
# ì „ì—­ ë³€ìˆ˜ë¡œ ì„ ì–¸í•˜ì—¬ í•¨ìˆ˜ ë‚´ì—ì„œ í• ë‹¹
tf = None
layers = None
models = None

def load_tf_dependencies():
    """TensorFlow ì˜ì¡´ì„±ì„ í•„ìš”í•  ë•Œ ë¡œë“œ"""
    global tf, layers, models
    if tf is None:
        try:
            import tensorflow as _tf
            from tensorflow.keras import layers as _layers
            from tensorflow.keras import models as _models
            tf = _tf
            layers = _layers
            models = _models
        except ImportError as e:
            st.error(f"TensorFlow ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.stop()
        except Exception as e:
            st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            st.stop()

def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.0):
    # layersê°€ ë¡œë“œëœ ìƒíƒœë¼ê³  ê°€ì •
    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)
    x = layers.Dropout(dropout)(x)
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    res = x + inputs
    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation="relu")(res)
    x = layers.Dropout(dropout)(x)
    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    return x + res

def build_action_model(input_shape, n_classes):
    # layers, models ì‚¬ìš©
    inputs = layers.Input(shape=input_shape)
    x = layers.Conv1D(64, kernel_size=3, padding="same", activation="relu")(inputs)
    x = layers.BatchNormalization()(x)
    for _ in range(2): 
        x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=128, dropout=0.3)
    x = layers.GlobalAveragePooling1D()(x)
    x = layers.Dropout(0.3)(x)
    x = layers.Dense(64, activation="relu")(x)
    outputs = layers.Dense(n_classes, activation="softmax")(x)
    return models.Model(inputs, outputs)

class StickerProcessor:
    def __init__(self, weights_path, device=DEVICE):
        self.model = YOLO(weights_path)
    
    def get_spine_points(self, img_arr, kps):
        if kps is None: return [], False, "Pose ì¸ì‹ ë¶ˆê°€"
        l_sh, r_sh = kps[5][:2], kps[6][:2]
        mid_x = (l_sh[0] + r_sh[0]) / 2
        results = self.model.predict(img_arr, verbose=False, conf=0.1)
        candidates = []
        if len(results) > 0 and results[0].boxes is not None:
            boxes = results[0].boxes.data.cpu().numpy()
            for box in boxes:
                cx, cy = (box[0] + box[2]) / 2, (box[1] + box[3]) / 2
                candidates.append({'center': (cx, cy), 'conf': box[4]})
        
        x_tol = abs(l_sh[0] - r_sh[0]) * 0.5
        valid_cands = [c for c in candidates if abs(c['center'][0] - mid_x) < x_tol]
        valid_cands.sort(key=lambda x: x['center'][1])
        
        if len(valid_cands) >= 2: return valid_cands, True, "ì„±ê³µ"
        return valid_cands, False, f"ìŠ¤í‹°ì»¤ ë¶€ì¡± ({len(valid_cands)}ê°œ)"

# ==========================================
# 2. ìœ í‹¸ë¦¬í‹° ë° ëª¨ë¸ ë¡œë”
# ==========================================
def angle_between(v1, v2):
    n1, n2 = np.linalg.norm(v1), np.linalg.norm(v2)
    if n1 == 0 or n2 == 0: return 0.0
    return float(np.degrees(np.arccos(np.clip(np.dot(v1, v2)/(n1*n2), -1.0, 1.0))))

def process_yolo_keypoints_original(kps):
    coords, confs = kps[:, :2].copy(), kps[:, 2:3].copy()
    coords -= (coords[11] + coords[12]) / 2.0
    scale_ref = np.linalg.norm((coords[5] + coords[6]) / 2.0) or 1.0
    coords /= scale_ref; coords[[13,14,15,16]] = 0.0
    return np.hstack([coords, confs]).flatten()

@st.cache_resource
def load_all_models():
    # 1. TensorFlow ì§€ì—° ë¡œë“œ
    load_tf_dependencies()
    
    # 2. ëª¨ë¸ ë¹Œë“œ
    pm = YOLO(POSE_MODEL_NAME)
    am = build_action_model((30, 51), 5)
    
    if os.path.exists(ACTION_WEIGHTS_PATH):
        with open(ACTION_WEIGHTS_PATH, "rb") as f: w_list = pickle.load(f)
        am.set_weights([np.array(w) for w in w_list])
    
    sp = StickerProcessor(STICKER_MODEL_PATH) if os.path.exists(STICKER_MODEL_PATH) else None
    
    return pm, am, ['Sitting (Ready)', 'Forward_Bending', 'Back_Extension', 'Side_Bending', 'Rotation'], sp

# ì„¸ì…˜ ë° ìƒíƒœ ì´ˆê¸°í™”
if 'last_kps' not in st.session_state: st.session_state['last_kps'] = None
if 'last_action' not in st.session_state: st.session_state['last_action'] = "Waiting..."
for k in ['calc_result']:
    if k not in st.session_state: st.session_state[k] = None

# ==========================================
# 3. WebRTC ë¡œì§
# ==========================================
# ëª¨ë¸ ì „ì—­ ë¡œë“œ (ìºì‹±ë¨)
try:
    pm_global, am_global, names_global, sp_global = load_all_models()
except Exception as e:
    st.error(f"ëª¨ë¸ ë¡œë”© ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
    img = frame.to_ndarray(format="bgr24")
    
    # Pose ì¶”ë¡ 
    res = pm_global(img, verbose=False, conf=0.1)
    kps = None
    action_text = "No Pose"
    
    if res[0].keypoints is not None and len(res[0].keypoints.data) > 0:
        kps = res[0].keypoints.data[0].cpu().numpy()
        
        # Action ì¶”ë¡  (TensorFlow)
        feat = process_yolo_keypoints_original(kps)
        feat_tensor = np.expand_dims(feat, axis=0)
        input_data = np.tile(feat_tensor, (1, 30, 1)) 
        
        pred = am_global.predict(input_data, verbose=0)
        action_idx = np.argmax(pred)
        action_text = names_global[action_idx]
        
    try:
        if kps is not None:
            if st.session_state.result_queue.full():
                st.session_state.result_queue.get_nowait()
            st.session_state.result_queue.put({'kps': kps, 'action': action_text})
    except:
        pass

    return frame

# ==========================================
# 4. UI êµ¬ì„±
# ==========================================
col_cam, col_info = st.columns([1.5, 1.0])

with col_cam:
    st.markdown("### ğŸ¥ ì›¹ìº  ìŠ¤íŠ¸ë¦¼ (WebRTC)")
    webrtc_ctx = webrtc_streamer(
        key="pose-analysis",
        mode=WebRtcMode.SENDRECV,
        rtc_configuration=RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}),
        video_frame_callback=video_frame_callback,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

with col_info:
    st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼")
    status_container = st.container()
    
    if webrtc_ctx.state.playing:
        try:
            data = st.session_state.result_queue.get(timeout=0.1)
            st.session_state['last_kps'] = data['kps']
            st.session_state['last_action'] = data['action']
        except queue.Empty:
            pass
            
    status_container.info(f"í˜„ì¬ ë™ì‘: **{st.session_state['last_action']}**")

    st.markdown("---")
    if st.button("ğŸ“¸ ìì„¸ ì¸¡ì • (Snap)", type="primary", use_container_width=True):
        if st.session_state['last_kps'] is not None:
            kps = st.session_state['last_kps']
            sh_vector = kps[6][:2] - kps[5][:2]
            hip_vector = kps[12][:2] - kps[11][:2]
            angle = angle_between(sh_vector, hip_vector)
            st.session_state['calc_result'] = f"ì–´ê¹¨-ê³¨ë°˜ ì •ë ¬: {angle:.1f}Â°"
        else:
            st.error("ë°ì´í„° ì—†ìŒ")

    if st.session_state['calc_result']:
        st.success(st.session_state['calc_result'])
