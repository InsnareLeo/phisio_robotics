import streamlit as st
import numpy as np
import pandas as pd
import pickle
import torch
import os
import queue
import av
import pathlib
import sys
from ultralytics import YOLO  # Pose ëª¨ë¸ìš© (v8)
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration

# ==========================================
# 0. í™˜ê²½ ë° ê²½ë¡œ ì„¤ì •
# ==========================================
# [ì¤‘ìš”] Linux(Cloud)ì—ì„œ Windows ê²½ë¡œë¡œ ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ ì‹œ ì˜¤ë¥˜ ë°©ì§€
pathlib.WindowsPath = pathlib.PosixPath

st.set_page_config(page_title="Phisio AI Pro (Cloud/v9)", layout="wide")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
POSE_MODEL_NAME = os.path.join(BASE_DIR, "yolov8n-pose.pt")
ACTION_WEIGHTS_PATH = os.path.join(BASE_DIR, "yoga_weights_yolo_seated_safe.pkl")
STICKER_MODEL_PATH = os.path.join(BASE_DIR, 'best.pt')

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

if 'result_queue' not in st.session_state:
    st.session_state.result_queue = queue.Queue(maxsize=1)

# ==========================================
# 1. TensorFlow Lazy Loading (ì˜¤ë¥˜ ë°©ì§€)
# ==========================================
tf = None
layers = None
models = None

def load_tf_dependencies():
    global tf, layers, models
    if tf is None:
        try:
            import tensorflow as _tf
            from tensorflow.keras import layers as _layers
            from tensorflow.keras import models as _models
            tf = _tf
            layers = _layers
            models = _models
        except ImportError:
            st.error("TensorFlow ë¡œë“œ ì‹¤íŒ¨. requirements.txtë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            st.stop()

# ==========================================
# 2. ëª¨ë¸ í´ë˜ìŠ¤ ì •ì˜
# ==========================================
def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.0):
    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)
    x = layers.Dropout(dropout)(x)
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    res = x + inputs
    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation="relu")(res)
    x = layers.Dropout(dropout)(x)
    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    return x + res

def build_action_model(input_shape, n_classes):
    inputs = layers.Input(shape=input_shape)
    x = layers.Conv1D(64, kernel_size=3, padding="same", activation="relu")(inputs)
    x = layers.BatchNormalization()(x)
    for _ in range(2): 
        x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=128, dropout=0.3)
    x = layers.GlobalAveragePooling1D()(x)
    x = layers.Dropout(0.3)(x)
    x = layers.Dense(64, activation="relu")(x)
    outputs = layers.Dense(n_classes, activation="softmax")(x)
    return models.Model(inputs, outputs)

class StickerProcessorV9:
    def __init__(self, weights_path, device=DEVICE):
        # [í•µì‹¬ ë³€ê²½] WongKinYiu/yolov9 ë ˆí¬ì§€í† ë¦¬ì—ì„œ êµ¬ì¡°ë¥¼ ë¶ˆëŸ¬ì™€ ë¡œë“œ
        # 'custom'ì„ ì‚¬ìš©í•˜ë©´ ë¡œì»¬ì˜ weights_path(.pt)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        try:
            # force_reload=TrueëŠ” ìºì‹œ ë¬¸ì œ ë°©ì§€ìš©
            self.model = torch.hub.load('WongKinYiu/yolov9', 'custom', path=weights_path, force_reload=False, trust_repo=True)
            self.model.conf = 0.15  # Confidence Threshold
            self.model.iou = 0.45   # NMS IoU Threshold
            self.model.eval()       # í‰ê°€ ëª¨ë“œ
            self.model.to(device)
        except Exception as e:
            st.error(f"YOLOv9 ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\n(ì¸í„°ë„· ì—°ê²°ì´ í•„ìš”í•˜ë©°, best.pt ê²½ë¡œê°€ ì •í™•í•´ì•¼ í•©ë‹ˆë‹¤)")
            self.model = None

    def get_spine_points(self, img_arr, kps):
        if kps is None or self.model is None: return [], False, "ì¸ì‹ ë¶ˆê°€"
        
        # 1. Pose ì¢Œí‘œ ì¶”ì¶œ
        l_sh, r_sh = kps[5][:2], kps[6][:2]
        mid_x = (l_sh[0] + r_sh[0]) / 2
        
        # 2. YOLOv9 ì¶”ë¡ 
        # torch.hub ëª¨ë¸ì€ ë‚´ë¶€ì ìœ¼ë¡œ ì „ì²˜ë¦¬(letterbox)ë¥¼ ìˆ˜í–‰í•˜ë¯€ë¡œ RGB ì´ë¯¸ì§€ë§Œ ë„˜ê¸°ë©´ ë¨
        try:
            # WebRTC í”„ë ˆì„(img_arr)ì€ BGR -> ëª¨ë¸ ì…ë ¥ì€ RGB
            img_rgb = img_arr[:, :, ::-1]
            results = self.model(img_rgb)
            
            # 3. ê²°ê³¼ íŒŒì‹± (Pandas)
            df = results.pandas().xyxy[0] # xmin, ymin, xmax, ymax, confidence, class, name
            
            candidates = []
            for _, row in df.iterrows():
                cx = (row['xmin'] + row['xmax']) / 2
                cy = (row['ymin'] + row['ymax']) / 2
                candidates.append({'center': (cx, cy), 'conf': row['confidence']})
            
            # 4. ì²™ì¶” ì¤‘ì‹¬ í•„í„°ë§
            x_tol = abs(l_sh[0] - r_sh[0]) * 0.6
            valid_cands = [c for c in candidates if abs(c['center'][0] - mid_x) < x_tol]
            valid_cands.sort(key=lambda x: x['center'][1]) # ìœ„ì—ì„œ ì•„ë˜ë¡œ ì •ë ¬
            
            if len(valid_cands) >= 2:
                return valid_cands, True, "ì„±ê³µ"
            return valid_cands, False, f"ë¶€ì¡± ({len(valid_cands)}ê°œ)"
            
        except Exception as e:
            return [], False, f"ì¶”ë¡  ì˜¤ë¥˜: {e}"

# ==========================================
# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
def process_yolo_keypoints_original(kps):
    coords, confs = kps[:, :2].copy(), kps[:, 2:3].copy()
    coords -= (coords[11] + coords[12]) / 2.0
    scale_ref = np.linalg.norm((coords[5] + coords[6]) / 2.0) or 1.0
    coords /= scale_ref; coords[[13,14,15,16]] = 0.0
    return np.hstack([coords, confs]).flatten()

@st.cache_resource
def load_all_models():
    # 1. TF ë¡œë“œ
    load_tf_dependencies()
    
    # 2. Pose Model (YOLOv8 - ê³µì‹ íŒ¨í‚¤ì§€)
    pm = YOLO(POSE_MODEL_NAME)
    
    # 3. Action Model (Keras)
    am = build_action_model((30, 51), 5)
    if os.path.exists(ACTION_WEIGHTS_PATH):
        with open(ACTION_WEIGHTS_PATH, "rb") as f: w_list = pickle.load(f)
        am.set_weights([np.array(w) for w in w_list])
    
    # 4. Sticker Model (YOLOv9 - Torch Hub)
    sp = StickerProcessorV9(STICKER_MODEL_PATH) if os.path.exists(STICKER_MODEL_PATH) else None
    
    return pm, am, ['Sitting (Ready)', 'Forward_Bending', 'Back_Extension', 'Side_Bending', 'Rotation'], sp

# ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
if 'last_kps' not in st.session_state: st.session_state['last_kps'] = None
if 'last_action' not in st.session_state: st.session_state['last_action'] = "Waiting..."
if 'sticker_info' not in st.session_state: st.session_state['sticker_info'] = None

# ==========================================
# 4. WebRTC ì½œë°±
# ==========================================
try:
    pm_global, am_global, names_global, sp_global = load_all_models()
except Exception as e:
    st.error(f"ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
    st.stop()

def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
    img = frame.to_ndarray(format="bgr24")
    
    # 1. Pose ì¶”ë¡ 
    res = pm_global(img, verbose=False, conf=0.1)
    kps = None
    action_text = "No Pose"
    
    if res[0].keypoints is not None and len(res[0].keypoints.data) > 0:
        kps = res[0].keypoints.data[0].cpu().numpy()
        
        # 2. Action ì¶”ë¡ 
        feat = process_yolo_keypoints_original(kps)
        feat_tensor = np.expand_dims(feat, axis=0)
        input_data = np.tile(feat_tensor, (1, 30, 1)) 
        pred = am_global.predict(input_data, verbose=0)
        action_idx = np.argmax(pred)
        action_text = names_global[action_idx]
    
    # 3. ë°ì´í„° ì „ì†¡
    try:
        if kps is not None:
            if st.session_state.result_queue.full():
                st.session_state.result_queue.get_nowait()
            st.session_state.result_queue.put({'kps': kps, 'action': action_text})
    except:
        pass

    return frame

# ==========================================
# 5. UI êµ¬ì„±
# ==========================================
col_cam, col_info = st.columns([1.5, 1.0])

with col_cam:
    st.markdown("### ğŸ¥ ì›¹ìº  ìŠ¤íŠ¸ë¦¼ (YOLOv9 Support)")
    webrtc_ctx = webrtc_streamer(
        key="pose-analysis-v9",
        mode=WebRtcMode.SENDRECV,
        rtc_configuration=RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}),
        video_frame_callback=video_frame_callback,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

with col_info:
    st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ë¶„ì„")
    status_cont = st.container()
    
    # í ë°ì´í„° ìˆ˜ì‹ 
    if webrtc_ctx.state.playing:
        try:
            data = st.session_state.result_queue.get(timeout=0.1)
            st.session_state['last_kps'] = data['kps']
            st.session_state['last_action'] = data['action']
        except queue.Empty:
            pass
            
    status_cont.info(f"ë™ì‘ ìƒíƒœ: **{st.session_state['last_action']}**")

    st.markdown("---")
    
    # YOLOv9 í…ŒìŠ¤íŠ¸ ë²„íŠ¼ (ì£¼ì˜: ì›¹ìº  ìº¡ì²˜ ëŒ€ì‹  ë§ˆì§€ë§‰ í¬ì¦ˆ ë°ì´í„°ë§Œ ì‚¬ìš© ê°€ëŠ¥)
    # Cloudì—ì„œ ì´ë¯¸ì§€ë¥¼ WebRTC ìŠ¤ë ˆë“œ ë°–ìœ¼ë¡œ êº¼ë‚´ëŠ” ê²ƒì€ ë§¤ìš° ëŠë¦¬ë¯€ë¡œ, 
    # v9 ëª¨ë¸ ë¡œë“œ ì„±ê³µ ì—¬ë¶€ë§Œ í™•ì¸í•˜ê±°ë‚˜ í¬ì¦ˆ ê¸°ë°˜ ê³„ì‚° ì¶”ì²œ.
    
    if st.button("ğŸ›  ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸", use_container_width=True):
        if sp_global and sp_global.model:
            st.success("âœ… YOLOv9 (WongKinYiu) ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.caption("Streamlit Cloudì—ì„œ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ì²˜ë¦¬í•˜ë ¤ë©´ ì´ë¯¸ì§€ ì—…ë¡œë“œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        else:
            st.error("âŒ ìŠ¤í‹°ì»¤ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨")

    if st.button("ğŸ“¸ ìì„¸ ê°ë„ ì¸¡ì • (Pose ê¸°ë°˜)", use_container_width=True):
         if st.session_state['last_kps'] is not None:
            kps = st.session_state['last_kps']
            sh_v = kps[6][:2] - kps[5][:2]
            angle = np.degrees(np.arctan2(sh_v[1], sh_v[0]))
            st.info(f"ì–´ê¹¨ ê¸°ìš¸ê¸°: {angle:.1f}Â°")
         else:
             st.warning("í¬ì¦ˆ ë°ì´í„°ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
