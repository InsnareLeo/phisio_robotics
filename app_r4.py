import streamlit as st
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models
import pickle
import torch
import os
import queue
import av
from collections import deque
from ultralytics import YOLO
from streamlit_webrtc import webrtc_streamer, WebRtcMode, RTCConfiguration

# ==========================================
# 0. í™˜ê²½ ë° ê²½ë¡œ ì„¤ì •
# ==========================================
st.set_page_config(page_title="Phisio AI Pro (Cloud)", layout="wide")

# CV2 ì œê±° ë° ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
POSE_MODEL_NAME = os.path.join(BASE_DIR, "yolov8n-pose.pt")
ACTION_WEIGHTS_PATH = os.path.join(BASE_DIR, "yoga_weights_yolo_seated_safe.pkl")
STICKER_MODEL_PATH = os.path.join(BASE_DIR, 'best.pt')

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

# ì‹¤ì‹œê°„ ë°ì´í„° ê³µìœ ë¥¼ ìœ„í•œ Queue (Thread-safe)
if 'result_queue' not in st.session_state:
    st.session_state.result_queue = queue.Queue(maxsize=1)

# ==========================================
# 1. ëª¨ë¸ ë° ì²˜ë¦¬ í´ë˜ìŠ¤
# ==========================================
def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0.0):
    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)
    x = layers.Dropout(dropout)(x)
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    res = x + inputs
    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation="relu")(res)
    x = layers.Dropout(dropout)(x)
    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)
    x = layers.LayerNormalization(epsilon=1e-6)(x)
    return x + res

def build_action_model(input_shape, n_classes):
    inputs = layers.Input(shape=input_shape)
    x = layers.Conv1D(64, kernel_size=3, padding="same", activation="relu")(inputs)
    x = layers.BatchNormalization()(x)
    for _ in range(2): 
        x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=128, dropout=0.3)
    x = layers.GlobalAveragePooling1D()(x)
    x = layers.Dropout(0.3)(x)
    x = layers.Dense(64, activation="relu")(x)
    outputs = layers.Dense(n_classes, activation="softmax")(x)
    return models.Model(inputs, outputs)

class StickerProcessor:
    def __init__(self, weights_path, device=DEVICE):
        # Ultralytics YOLO ë„¤ì´í‹°ë¸Œ ë¡œë“œ (CV2 ì˜ì¡´ì„± ì œê±°)
        self.model = YOLO(weights_path)
    
    def get_spine_points(self, img_arr, kps):
        # kps: Pose Keypoints
        if kps is None: return [], False, "Pose ì¸ì‹ ë¶ˆê°€"
        
        # 1. Pose ê¸°ì¤€ ROI ì„¤ì • (Numpy ì—°ì‚°)
        l_sh, r_sh = kps[5][:2], kps[6][:2]
        mid_x = (l_sh[0] + r_sh[0]) / 2
        
        # 2. ìŠ¤í‹°ì»¤ ëª¨ë¸ ì¶”ë¡  (Ultralytics ë‚´ë¶€ ì „ì²˜ë¦¬ ì‚¬ìš©)
        results = self.model.predict(img_arr, verbose=False, conf=0.1)
        
        # 3. ê²°ê³¼ íŒŒì‹± (Boxes -> Numpy)
        candidates = []
        if len(results) > 0 and results[0].boxes is not None:
            boxes = results[0].boxes.data.cpu().numpy()  # [x1, y1, x2, y2, conf, cls]
            for box in boxes:
                cx = (box[0] + box[2]) / 2
                cy = (box[1] + box[3]) / 2
                candidates.append({'center': (cx, cy), 'conf': box[4]})
        
        # 4. ì²™ì¶” í¬ì¸íŠ¸ í•„í„°ë§ ë¡œì§ (ê°„ì†Œí™”ë¨)
        # ì¤‘ì‹¬ì¶•(mid_x)ì—ì„œ ë„ˆë¬´ ë¨¼ ê²ƒì€ ì œì™¸
        x_tol = abs(l_sh[0] - r_sh[0]) * 0.5
        valid_cands = [c for c in candidates if abs(c['center'][0] - mid_x) < x_tol]
        
        # Yì¶• ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìœ„ -> ì•„ë˜)
        valid_cands.sort(key=lambda x: x['center'][1])
        
        if len(valid_cands) >= 2: # ìµœì†Œ 2ê°œ ì´ìƒì´ë©´ ê³„ì‚° ê°€ëŠ¥ìœ¼ë¡œ ê°„ì£¼
            return valid_cands, True, "ì„±ê³µ"
        return valid_cands, False, f"ìŠ¤í‹°ì»¤ ë¶€ì¡± ({len(valid_cands)}ê°œ)"

# ==========================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
def angle_between(v1, v2):
    n1, n2 = np.linalg.norm(v1), np.linalg.norm(v2)
    if n1 == 0 or n2 == 0: return 0.0
    return float(np.degrees(np.arccos(np.clip(np.dot(v1, v2)/(n1*n2), -1.0, 1.0))))

def process_yolo_keypoints_original(kps):
    # Numpy ì—°ì‚°ë§Œ ì‚¬ìš©
    coords, confs = kps[:, :2].copy(), kps[:, 2:3].copy()
    coords -= (coords[11] + coords[12]) / 2.0
    scale_ref = np.linalg.norm((coords[5] + coords[6]) / 2.0) or 1.0
    coords /= scale_ref; coords[[13,14,15,16]] = 0.0
    return np.hstack([coords, confs]).flatten()

@st.cache_resource
def load_all_models():
    # Pose Model
    pm = YOLO(POSE_MODEL_NAME)
    
    # Action Model
    am = build_action_model((30, 51), 5)
    if os.path.exists(ACTION_WEIGHTS_PATH):
        with open(ACTION_WEIGHTS_PATH, "rb") as f: w_list = pickle.load(f)
        am.set_weights([np.array(w) for w in w_list])
    
    # Sticker Model
    sp = StickerProcessor(STICKER_MODEL_PATH) if os.path.exists(STICKER_MODEL_PATH) else None
    
    return pm, am, ['Sitting (Ready)', 'Forward_Bending', 'Back_Extension', 'Side_Bending', 'Rotation'], sp

# ì„¸ì…˜ ì´ˆê¸°í™”
if 'last_kps' not in st.session_state: st.session_state['last_kps'] = None
if 'last_action' not in st.session_state: st.session_state['last_action'] = "Waiting..."
for k in ['side_baseline_vec', 'rot_baseline_vec', 'error_msg', 'calc_result']:
    if k not in st.session_state: st.session_state[k] = None

# ==========================================
# 3. WebRTC ì½œë°± (ë³„ë„ ìŠ¤ë ˆë“œ)
# ==========================================
# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ë¡œë“œ (ìŠ¤ë ˆë“œ ì ‘ê·¼ìš©)
pm_global, am_global, names_global, sp_global = load_all_models()

def video_frame_callback(frame: av.VideoFrame) -> av.VideoFrame:
    img = frame.to_ndarray(format="bgr24")
    
    # 1. Pose ì¶”ë¡ 
    res = pm_global(img, verbose=False, conf=0.1)
    kps = None
    action_text = "No Pose"
    
    if res[0].keypoints is not None and len(res[0].keypoints.data) > 0:
        kps = res[0].keypoints.data[0].cpu().numpy()
        
        # 2. Action ì¶”ë¡ 
        feat = process_yolo_keypoints_original(kps)
        feat_tensor = np.expand_dims(feat, axis=0) # (1, 51)
        # Action ëª¨ë¸ ì…ë ¥ ì°¨ì› (Batch, Time, Features) -> (1, 30, 51) í•„ìš”
        # ë‹¨ì¼ í”„ë ˆì„ ì²˜ë¦¬ ë¡œì§: 30í”„ë ˆì„ ë²„í¼ê°€ ì—†ìœ¼ë©´ ë³µì œ
        input_data = np.tile(feat_tensor, (1, 30, 1)) 
        
        pred = am_global.predict(input_data, verbose=0)
        action_idx = np.argmax(pred)
        action_text = names_global[action_idx]
        
    # 3. ë©”ì¸ ìŠ¤ë ˆë“œë¡œ ë°ì´í„° ì „ì†¡ (ì´ë¯¸ì§€ ê·¸ë¦¬ê¸° ì—†ìŒ)
    try:
        if kps is not None:
            # íì— ìµœì‹  ë°ì´í„° ë®ì–´ì“°ê¸°
            if st.session_state.result_queue.full():
                st.session_state.result_queue.get_nowait()
            st.session_state.result_queue.put({'kps': kps, 'action': action_text})
    except:
        pass

    return frame

# ==========================================
# 4. ë©”ì¸ UI
# ==========================================
col_cam, col_info = st.columns([1.5, 1.0])

with col_cam:
    st.markdown("### ğŸ¥ ì›¹ìº  ìŠ¤íŠ¸ë¦¼ (WebRTC)")
    # WebRTC ìŠ¤íŠ¸ë¦¬ë¨¸ ì„¤ì •
    webrtc_ctx = webrtc_streamer(
        key="pose-analysis",
        mode=WebRtcMode.SENDRECV,
        rtc_configuration=RTCConfiguration({"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}),
        video_frame_callback=video_frame_callback,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
    )

with col_info:
    st.subheader("ğŸ“Š ì‹¤ì‹œê°„ ë¶„ì„ ê²°ê³¼")
    
    # ì‹¤ì‹œê°„ ì •ë³´ í‘œì‹œìš© ì»¨í…Œì´ë„ˆ
    status_container = st.container()
    result_container = st.empty()
    
    # íì—ì„œ ë°ì´í„° í´ë§ ë° ì„¸ì…˜ ì—…ë°ì´íŠ¸
    if webrtc_ctx.state.playing:
        try:
            data = st.session_state.result_queue.get(timeout=0.1)
            st.session_state['last_kps'] = data['kps']
            st.session_state['last_action'] = data['action']
        except queue.Empty:
            pass
            
    status_container.info(f"í˜„ì¬ ë™ì‘: **{st.session_state['last_action']}**")

    st.markdown("---")
    st.subheader("ğŸ› ï¸ ì¸¡ì • ë„êµ¬")

    # Cobb ê°ë„ (ë°ì´í„° ê¸°ë°˜ ê³„ì‚°)
    if st.button("ğŸ“¸ Cobb ê°ë„ ì¸¡ì • (Side Baseline)", type="primary", use_container_width=True):
        if st.session_state['last_kps'] is not None and sp_global:
            # í˜„ì¬ í”„ë ˆì„ ì´ë¯¸ì§€ëŠ” ì—†ìœ¼ë¯€ë¡œ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±í•˜ì—¬ ìœ„ì¹˜ë§Œ íŒŒì•… (ë˜ëŠ” ë¡œì§ ë¶„ë¦¬)
            # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ KPSì™€ Sticker ìœ„ì¹˜ ê´€ê³„ë§Œ ê³„ì‚°í•´ì•¼ í•˜ì§€ë§Œ, 
            # Sticker ëª¨ë¸ì€ ì´ë¯¸ì§€ê°€ í•„ìš”í•¨.
            # *ì œì•½ì‚¬í•­*: WebRTC ì½œë°± ë°–ì—ì„œëŠ” ì´ë¯¸ì§€ë¥¼ ì–»ê¸° ì–´ë ¤ì›€.
            # ë”°ë¼ì„œ 'snapshot' ëŒ€ì‹  'ë§ˆì§€ë§‰ ì¸ì‹ëœ ìƒíƒœ'ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì•ˆë‚´
            st.warning("âš ï¸ Cloud ëª¨ë“œ: ì´ë¯¸ì§€ ìº¡ì²˜ ëŒ€ì‹  ì‹¤ì‹œê°„ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            
            # (Note: ì‹¤ì œ ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ Sticker ëª¨ë¸ì„ ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 
            #  Cloud WebRTC êµ¬ì¡°ìƒ ì´ë¯¸ì§€ë¥¼ ë©”ì¸ ìŠ¤ë ˆë“œë¡œ ê°€ì ¸ì˜¤ëŠ” ê²ƒì€ ëŒ€ì—­í­ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.
            #  ë”°ë¼ì„œ ì´ ê¸°ëŠ¥ì€ 'Pose Keypoint' ê¸°ë°˜ì˜ ê°„ë‹¨í•œ ê°ë„ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ 
            #  ê¸°ëŠ¥ ì œí•œ ë©”ì‹œì§€ë¥¼ ë„ìš°ëŠ” ê²ƒì´ ì•ˆì „í•©ë‹ˆë‹¤.)
            
            # ì—¬ê¸°ì„œëŠ” ë™ì‘ í™•ì¸ì„ ìœ„í•´ Pose ë°ì´í„°ë¡œ ëŒ€ì²´ ê³„ì‚° ì˜ˆì‹œ
            kps = st.session_state['last_kps']
            sh_vector = kps[6][:2] - kps[5][:2] # ì–´ê¹¨ ê¸°ìš¸ê¸°
            hip_vector = kps[12][:2] - kps[11][:2] # ê³¨ë°˜ ê¸°ìš¸ê¸°
            # ê°„ë‹¨í•œ ì²™ì¶” ì •ë ¬ ê°ë„ (ëŒ€ì²´)
            angle = angle_between(sh_vector, hip_vector)
            st.session_state['calc_result'] = f"ìƒì²´-í•˜ì²´ ì •ë ¬ ê°ë„: {angle:.1f}Â°"
        else:
            st.error("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì›¹ìº ì´ ì¼œì ¸ ìˆë‚˜ìš”?")

    if st.session_state['calc_result']:
        st.success(st.session_state['calc_result'])

    st.markdown("---")
    st.caption("â€» Streamlit Cloud í™˜ê²½ì—ì„œëŠ” cv2 ê·¸ë˜í”½ ì²˜ë¦¬ê°€ ì œí•œë˜ì–´ í…ìŠ¤íŠ¸ ê²°ê³¼ë§Œ ì œê³µë©ë‹ˆë‹¤.")
